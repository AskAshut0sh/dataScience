{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our recommender system will generate recommendations in the following way:\n",
    "1. Generate a course set of candidate items (e.g. 100).\n",
    "2. Filter bad candidate items (e.g. items the the user has already bought).\n",
    "3. Rank candidate items.\n",
    "\n",
    "In this notebook, we will build a model for the first step. Our model will be based on the two-tower architecture, which trains query (user) embeddings to be close to candidate (item) embeddings in a shared space. The idea is that the embedding of a user should be close to all the embeddings of items the user has previously bought.\n",
    "\n",
    "Let's go ahead and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dtype = {\"user_id\": object, \"item_id\": object}\n",
    "\n",
    "train_df = pd.read_csv(\"train_df.csv\", dtype=dtype)\n",
    "val_df = pd.read_csv(\"val_df.csv\", dtype=dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our retrieval model with a subset of features.\n",
    "\n",
    "For the query embedding we will use:\n",
    "- `user_id`: ID of the customer.\n",
    "- `age`: age of the customer at the time of purchase.\n",
    "- `month_sin`, `month_cos`: time of year the purchase was made.\n",
    "\n",
    "For the candidate embedding we will use:\n",
    "- `item_id`: ID of the item.\n",
    "- `garment_group_name`: type of garment.\n",
    "- `index_group_name`: menswear/ladieswear etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_features = [\"user_id\", \"item_id\", \"age\", \"month_sin\",\n",
    "                      \"month_cos\", \"garment_group_name\", \"index_group_name\"]\n",
    "train_df = train_df[retrieval_features]\n",
    "val_df = val_df[retrieval_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a list of user and item IDs to initialize out embeddings.\n",
    "Garment group list and index group list are for the one-hot encodings (will be fixed in Hopsworks later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 672,157\n",
      "Number of users: 32,353\n",
      "Number of items: 64,267\n"
     ]
    }
   ],
   "source": [
    "user_id_list = train_df[\"user_id\"].unique().tolist()\n",
    "item_id_list = train_df[\"item_id\"].unique().tolist()\n",
    "garment_group_list = train_df[\"garment_group_name\"].unique().tolist()\n",
    "index_group_list = train_df[\"index_group_name\"].unique().tolist()\n",
    "\n",
    "print(f\"Number of transactions: {len(train_df):,}\")\n",
    "print(f\"Number of users: {len(user_id_list):,}\")\n",
    "print(f\"Number of items: {len(item_id_list):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 07:21:00.358006: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def df_to_ds(df):\n",
    "    return tf.data.Dataset.from_tensor_slices({col : df[col] for col in df})\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "ds_train = df_to_ds(train_df).batch(BATCH_SIZE).cache().shuffle(BATCH_SIZE*10)\n",
    "ds_val = df_to_ds(val_df).batch(BATCH_SIZE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a check that it works.\n",
    "# list(ds_train.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we specify the dimensionalty of our embeddings. Here we choose a relatively small dimensionality to prevent overfitting on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSION = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create the actual models. We will create three models:\n",
    "- Query model: generates a query representation given user and transaction features.\n",
    "- Candidate model: generates an item representation given item features.\n",
    "- Two tower model: trains the query and candidate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class UserTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=user_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # We add an additional embedding to account for unknown tokens.\n",
    "                len(user_id_list) + 1,\n",
    "                EMBEDDING_DIMENSION\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.normalized_age = tf.keras.layers.Normalization(axis=None)\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(EMBEDDING_DIMENSION, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(EMBEDDING_DIMENSION)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            tf.reshape(self.normalized_age(inputs[\"age\"]), (-1,1)),\n",
    "            tf.reshape(inputs[\"month_sin\"], (-1,1)),\n",
    "            tf.reshape(inputs[\"month_cos\"], (-1,1))\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "user_model = UserTower()\n",
    "user_model.normalized_age.adapt(ds_train.map(lambda x : x[\"age\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=item_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # We add an additional embedding to account for unknown tokens.\n",
    "                len(item_id_list) + 1,\n",
    "                EMBEDDING_DIMENSION\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.garment_group_tokenizer = tf.keras.layers.StringLookup(vocabulary=garment_group_list, mask_token=None)\n",
    "        self.index_group_tokenizer = tf.keras.layers.StringLookup(vocabulary=index_group_list, mask_token=None)\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(EMBEDDING_DIMENSION, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(EMBEDDING_DIMENSION)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        garment_group_embedding = tf.one_hot(\n",
    "            self.garment_group_tokenizer(inputs[\"garment_group_name\"]),\n",
    "            len(garment_group_list)\n",
    "        )\n",
    "\n",
    "        index_group_embedding = tf.one_hot(\n",
    "            self.index_group_tokenizer(inputs[\"index_group_name\"]),\n",
    "            len(index_group_list)\n",
    "        )\n",
    "\n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.item_embedding(inputs[\"item_id\"]),\n",
    "            garment_group_embedding,\n",
    "            index_group_embedding\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "item_model = ItemTower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "item_df = train_df[[\"item_id\", \"garment_group_name\", \"index_group_name\"]].drop_duplicates(subset=\"item_id\")\n",
    "\n",
    "# Convert item_list to dataset.\n",
    "item_ds = tf.data.Dataset.from_tensor_slices({col : item_df[col] for col in item_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change variable name of user, item model to query, candidate model.\n",
    "\n",
    "class TwoTowerModel(tf.keras.Model):\n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        self.user_model = user_model\n",
    "        self.item_model = item_model\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=item_ds.batch(BATCH_SIZE).map(self.item_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def train_step(self, batch) -> tf.Tensor:\n",
    "        # Set up a gradient tape to record gradients.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Loss computation.\n",
    "            user_embeddings = self.user_model(batch)\n",
    "            item_embeddings = self.item_model(batch)\n",
    "            loss = self.task(user_embeddings, item_embeddings,\n",
    "                             compute_metrics=False)\n",
    "\n",
    "            # Handle regularization losses as well.\n",
    "            regularization_loss = sum(self.losses)\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        metrics = {\n",
    "            \"loss\": loss,\n",
    "            \"regularization_loss\": regularization_loss,\n",
    "            \"total_loss\": total_loss\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch) -> tf.Tensor:\n",
    "        # Loss computation.\n",
    "        user_embeddings = self.user_model(batch)\n",
    "        item_embeddings = self.item_model(batch)\n",
    "\n",
    "        loss = self.task(user_embeddings, item_embeddings,\n",
    "                         compute_metrics=True)\n",
    "\n",
    "        # Handle regularization losses as well.\n",
    "        regularization_loss = sum(self.losses)\n",
    "\n",
    "        total_loss = loss + regularization_loss\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        # metrics = {}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "model = TwoTowerModel(user_model, item_model)\n",
    "# optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "optimizer = tfa.optimizers.AdamW(0.001, learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "329/329 [==============================] - 164s 490ms/step - loss: 14516.1378 - regularization_loss: 0.0000e+00 - total_loss: 14516.1378 - val_factorized_top_k/top_1_categorical_accuracy: 5.1030e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0030 - val_factorized_top_k/top_10_categorical_accuracy: 0.0054 - val_factorized_top_k/top_50_categorical_accuracy: 0.0190 - val_factorized_top_k/top_100_categorical_accuracy: 0.0324 - val_loss: 8672.8105 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8672.8105\n",
      "Epoch 2/5\n",
      "329/329 [==============================] - 181s 552ms/step - loss: 13553.4794 - regularization_loss: 0.0000e+00 - total_loss: 13553.4794 - val_factorized_top_k/top_1_categorical_accuracy: 6.3527e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0035 - val_factorized_top_k/top_10_categorical_accuracy: 0.0061 - val_factorized_top_k/top_50_categorical_accuracy: 0.0217 - val_factorized_top_k/top_100_categorical_accuracy: 0.0367 - val_loss: 8511.4258 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8511.4258\n",
      "Epoch 3/5\n",
      "329/329 [==============================] - 176s 537ms/step - loss: 13043.4102 - regularization_loss: 0.0000e+00 - total_loss: 13043.4102 - val_factorized_top_k/top_1_categorical_accuracy: 8.4702e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0039 - val_factorized_top_k/top_10_categorical_accuracy: 0.0067 - val_factorized_top_k/top_50_categorical_accuracy: 0.0224 - val_factorized_top_k/top_100_categorical_accuracy: 0.0372 - val_loss: 8456.4648 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8456.4648\n",
      "Epoch 4/5\n",
      "329/329 [==============================] - 167s 509ms/step - loss: 12699.3213 - regularization_loss: 0.0000e+00 - total_loss: 12699.3213 - val_factorized_top_k/top_1_categorical_accuracy: 8.9215e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0044 - val_factorized_top_k/top_10_categorical_accuracy: 0.0073 - val_factorized_top_k/top_50_categorical_accuracy: 0.0241 - val_factorized_top_k/top_100_categorical_accuracy: 0.0395 - val_loss: 8429.5420 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8429.5420\n",
      "Epoch 5/5\n",
      "329/329 [==============================] - 161s 491ms/step - loss: 12436.2547 - regularization_loss: 0.0000e+00 - total_loss: 12436.2547 - val_factorized_top_k/top_1_categorical_accuracy: 9.8935e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0046 - val_factorized_top_k/top_10_categorical_accuracy: 0.0082 - val_factorized_top_k/top_50_categorical_accuracy: 0.0256 - val_factorized_top_k/top_100_categorical_accuracy: 0.0414 - val_loss: 8454.4346 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8454.4346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x125740f40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, validation_data=ds_val, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we save our models. During inference we will use the item tower to genererate a query embedding. The items associated with the top-k closest candidate embeddings will serve as candidates. These will then be filtered by some criteria (e.g. do not recommend items the customer has already bought), and ranked by a so-called *ranking model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 07:36:08.308950: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: user_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.user_model.save(\"user_model\")\n",
    "model.item_model.save(\"item_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the top-k closest candidate embeddings in a brute-force way (computing the distances between the query embedding and all candidate embeddings) would be too expensive in a practical setting. In the next notebook, we will index the item embeddings using OpenSearch, which will allow us to retrieve candidates with very low latency."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
