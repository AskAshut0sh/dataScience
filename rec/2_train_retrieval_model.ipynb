{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Retrieval Model\n",
    "\n",
    "In this notebook, we will train a retrieval model that will be able to quickly generate a small subset of candidate items from a large collection of items. Our model will be based on the two-tower architecture, which embeds queries and candidates (keys) into a shared low-dimensional vector space. Here, a query consists of features of a customer and a transaction (e.g. timestamp of the purchase), whereas a candidate consists of features of a particular item. All queries will have a user ID and all candidates will have an item ID, and the model will be trained such that the embedding of a user will be close to all the embeddings of items the user has previously bought.\n",
    "\n",
    "### Data\n",
    "\n",
    "Let's go ahead and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dtype = {\"customer_id\": object, \"article_id\": object}\n",
    "\n",
    "train_df = pd.read_csv(\"train_df.csv\", dtype=dtype)\n",
    "val_df = pd.read_csv(\"val_df.csv\", dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our retrieval model with a subset of features.\n",
    "\n",
    "For the query embedding we will use:\n",
    "- `customer_id`: ID of the customer.\n",
    "- `age`: age of the customer at the time of purchase.\n",
    "- `month_sin`, `month_cos`: time of year the purchase was made.\n",
    "\n",
    "For the candidate embedding we will use:\n",
    "- `article_id`: ID of the item.\n",
    "- `garment_group_name`: type of garment.\n",
    "- `index_group_name`: menswear/ladieswear etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 16:26:36.922605: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "query_features = [\"customer_id\", \"age\", \"month_sin\", \"month_cos\"]\n",
    "candidate_features = [\"article_id\", \"garment_group_name\", \"index_group_name\"]\n",
    "\n",
    "retrieval_features = query_features + candidate_features\n",
    "\n",
    "train_df = train_df[retrieval_features]\n",
    "val_df = val_df[retrieval_features]\n",
    "\n",
    "def df_to_ds(df):\n",
    "    return tf.data.Dataset.from_tensor_slices({col : df[col] for col in df})\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "ds_train = df_to_ds(train_df).batch(BATCH_SIZE).cache().shuffle(BATCH_SIZE*10)\n",
    "ds_val = df_to_ds(val_df).batch(BATCH_SIZE).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a list of user and item IDs when we initialize our embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 409,857\n",
      "Number of users: 23,838\n",
      "Number of items: 56,690\n"
     ]
    }
   ],
   "source": [
    "user_id_list = train_df[\"customer_id\"].unique().tolist()\n",
    "item_id_list = train_df[\"article_id\"].unique().tolist()\n",
    "\n",
    "# TODO will be handled by Hopsworks when we create dataset with label encoder.\n",
    "garment_group_list = train_df[\"garment_group_name\"].unique().tolist()\n",
    "index_group_list = train_df[\"index_group_name\"].unique().tolist()\n",
    "\n",
    "print(f\"Number of transactions: {len(train_df):,}\")\n",
    "print(f\"Number of users: {len(user_id_list):,}\")\n",
    "print(f\"Number of items: {len(item_id_list):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Tower Model\n",
    "\n",
    "The two tower model consist of two models:\n",
    "- Query model: generates a query representation given user and transaction features.\n",
    "- Candidate model: generates an item representation given item features.\n",
    "\n",
    "Both models produce embeddings that live in the same embedding space. We let this space be low-dimensional to prevent overfitting on the training data. (Otherwise, the model might simply memorize previous purchases, which makes it recommend items customers already have bought.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with creating the query model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2048, 16), dtype=float32, numpy=\n",
       "array([[ 0.5593176 , -0.0049925 ,  0.09828547, ..., -0.34590882,\n",
       "         0.00600495,  0.16044746],\n",
       "       [ 0.43364993, -0.11357062,  0.10666486, ..., -0.21101117,\n",
       "         0.01319867,  0.11278725],\n",
       "       [-0.17184407,  0.21663298, -0.08368293, ..., -0.26022148,\n",
       "        -0.23559812, -0.06363247],\n",
       "       ...,\n",
       "       [-0.13941592,  0.17771576,  0.11363616, ..., -0.13024214,\n",
       "        -0.2633681 ,  0.06311373],\n",
       "       [ 0.18995321,  0.26337442, -0.16955397, ..., -0.6095935 ,\n",
       "         0.14430802,  0.20826371],\n",
       "       [ 0.10882069,  0.43169028, -0.27546012, ..., -1.0224997 ,\n",
       "         0.26312116,  0.09213994]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class UserTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=user_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # We add an additional embedding to account for unknown tokens.\n",
    "                len(user_id_list) + 1,\n",
    "                EMB_DIM\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.normalized_age = tf.keras.layers.Normalization(axis=None)\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(EMB_DIM, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(EMB_DIM)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.user_embedding(inputs[\"customer_id\"]),\n",
    "            tf.reshape(self.normalized_age(inputs[\"age\"]), (-1,1)),\n",
    "            tf.reshape(inputs[\"month_sin\"], (-1,1)),\n",
    "            tf.reshape(inputs[\"month_cos\"], (-1,1))\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "user_model = UserTower()\n",
    "\n",
    "# TODO this will be done in Hopsworks with the min-max scaler.\n",
    "user_model.normalized_age.adapt(ds_train.map(lambda x : x[\"age\"]))\n",
    "\n",
    "# Initialize model with inputs.\n",
    "query_ds = ds_train.map(lambda x : {feat : x[feat] for feat in query_features})\n",
    "user_model(next(iter(query_ds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The candidate model is very similar to the query model. A difference is that it has two categorical features as input, which we one-hot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=item_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # We add an additional embedding to account for unknown tokens.\n",
    "                len(item_id_list) + 1,\n",
    "                EMB_DIM\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.garment_group_tokenizer = tf.keras.layers.StringLookup(vocabulary=garment_group_list, mask_token=None)\n",
    "        self.index_group_tokenizer = tf.keras.layers.StringLookup(vocabulary=index_group_list, mask_token=None)\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(EMB_DIM, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(EMB_DIM)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        garment_group_embedding = tf.one_hot(\n",
    "            self.garment_group_tokenizer(inputs[\"garment_group_name\"]),\n",
    "            len(garment_group_list)\n",
    "        )\n",
    "\n",
    "        index_group_embedding = tf.one_hot(\n",
    "            self.index_group_tokenizer(inputs[\"index_group_name\"]),\n",
    "            len(index_group_list)\n",
    "        )\n",
    "\n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.item_embedding(inputs[\"article_id\"]),\n",
    "            garment_group_embedding,\n",
    "            index_group_embedding\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "item_model = ItemTower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate the two tower model using the *top-100 accuracy*. That is, for each transaction in the validation data we will generate the associated query embedding and retrieve the set of the 100 items that are closest to this query in the embedding space. The top-100 accuracy measures how often the item that was actually bought is part of this subset. To evaluate this, we create a dataset of all unique items in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacob/Library/Python/3.8/lib/python/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "item_df = train_df[candidate_features]\n",
    "item_df.drop_duplicates(subset=\"article_id\", inplace=True)\n",
    "item_ds = df_to_ds(item_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in place, we can finally create our two tower model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "class TwoTowerModel(tf.keras.Model):\n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        self.user_model = user_model\n",
    "        self.item_model = item_model\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=item_ds.batch(BATCH_SIZE).map(self.item_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def train_step(self, batch) -> tf.Tensor:\n",
    "        # Set up a gradient tape to record gradients.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Loss computation.\n",
    "            user_embeddings = self.user_model(batch)\n",
    "            item_embeddings = self.item_model(batch)\n",
    "            loss = self.task(user_embeddings, item_embeddings,\n",
    "                             compute_metrics=False)\n",
    "\n",
    "            # Handle regularization losses as well.\n",
    "            regularization_loss = sum(self.losses)\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        metrics = {\n",
    "            \"loss\": loss,\n",
    "            \"regularization_loss\": regularization_loss,\n",
    "            \"total_loss\": total_loss\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch) -> tf.Tensor:\n",
    "        # Loss computation.\n",
    "        user_embeddings = self.user_model(batch)\n",
    "        item_embeddings = self.item_model(batch)\n",
    "\n",
    "        loss = self.task(user_embeddings, item_embeddings,\n",
    "                         compute_metrics=True)\n",
    "\n",
    "        # Handle regularization losses as well.\n",
    "        regularization_loss = sum(self.losses)\n",
    "\n",
    "        total_loss = loss + regularization_loss\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "\n",
    "We'll train our model using the AdamW optimizer, which applies weight regularization during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "model = TwoTowerModel(user_model, item_model)\n",
    "optimizer = tfa.optimizers.AdamW(0.001, learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "201/201 [==============================] - 30s 139ms/step - loss: 14676.3919 - regularization_loss: 0.0000e+00 - total_loss: 14676.3919 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 10448.3174 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10448.3174\n",
      "Epoch 2/5\n",
      "201/201 [==============================] - 27s 135ms/step - loss: 13551.3349 - regularization_loss: 0.0000e+00 - total_loss: 13551.3349 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 10198.2305 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10198.2305\n",
      "Epoch 3/5\n",
      "201/201 [==============================] - 27s 136ms/step - loss: 12821.4571 - regularization_loss: 0.0000e+00 - total_loss: 12821.4571 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 10185.0850 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10185.0850\n",
      "Epoch 4/5\n",
      "201/201 [==============================] - 27s 136ms/step - loss: 12289.9572 - regularization_loss: 0.0000e+00 - total_loss: 12289.9572 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 10243.7949 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10243.7949\n",
      "Epoch 5/5\n",
      "201/201 [==============================] - 27s 135ms/step - loss: 11896.9813 - regularization_loss: 0.0000e+00 - total_loss: 11896.9813 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 10370.8965 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10370.8965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10f63e220>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, validation_data=ds_val, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we save our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 16:29:03.879201: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: user_model/assets\n",
      "INFO:tensorflow:Assets written to: item_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.user_model.save(\"user_model\")\n",
    "model.item_model.save(\"item_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "Retrieving the top-k closest candidate embeddings in a brute-force way (computing the distances between the query embedding and all candidate embeddings) is too expensive in a practical setting. In the next notebook, we will index the item embeddings using OpenSearch, which will allow us to retrieve candidates with very low latency."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
