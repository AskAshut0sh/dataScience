{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4402fa",
   "metadata": {},
   "source": [
    "This example shows how to generate recommendations for a user with a given `customer_id`.\n",
    "You also need to specify the month you want to generate recommendations for\n",
    "(recommendations for winter months and summer months should differ greatly).\n",
    "\n",
    "I wrote this code to sanity check that everything works.\n",
    "The code should be rewritten as transformer scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db637154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hsfs\n",
    "\n",
    "conn = hsfs.connection()\n",
    "fs = conn.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9040ff43",
   "metadata": {},
   "source": [
    "## Initialize Feature Views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185471d",
   "metadata": {},
   "source": [
    "(Skip this part if you've already initialized these features views.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_fg = fs.get_feature_group(\"customers\")\n",
    "articles_fg = fs.get_feature_group(\"articles\")\n",
    "\n",
    "customer_fv = fs.create_feature_view(\n",
    "    name='customers_fv',\n",
    "    query=customers_fg.select_all()\n",
    ")\n",
    "\n",
    "articles_fv = fs.create_feature_view(\n",
    "    name='articles_fv',\n",
    "    query=articles_fg.select_all()\n",
    ")\n",
    "\n",
    "customer_fv.init_serving()\n",
    "articles_fv.init_serving(batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9dad75",
   "metadata": {},
   "source": [
    "## Retrieve Candidate Items\n",
    "\n",
    "We will retrieve 100 candidate items. To do this we must.\n",
    "1. Generate a query embedding of the user.\n",
    "2. Find the 100 closest item embeddings to the query embedding.\n",
    "\n",
    "For the first part we need to:\n",
    "- Preprocess \"month of purchase\" feature.\n",
    "- Retrieve the \"age\" feature from customers_fv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d450f0a3",
   "metadata": {},
   "source": [
    "We start with an arbitrary user ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dfd0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = \"f6e35e1902674780464e8bc0f809cb5ae14883212b4f68b35b31de2facdb846f\"\n",
    "\n",
    "# Let's say the customer buys something in July.\n",
    "month_of_purchase = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff54596",
   "metadata": {},
   "source": [
    "and by the end of the notebook we will have some recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0997ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_features = {\"customer_id\" : customer_id}\n",
    "\n",
    "# Retrieve customer features (age, postal_code) of customer with id customer_id.\n",
    "customer_fv = fs.get_feature_view(\"customers_fv\", 1)\n",
    "\n",
    "customer_features = customer_fv.get_feature_vector({\"customer_id\" : customer_id})\n",
    "\n",
    "query_features[\"age\"] = customer_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we need to preprocess the month of the purchase.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def month_to_unit_circle(month):\n",
    "    zero_indexed_month = month - 1\n",
    "    C = 2*np.pi/12\n",
    "    month_sin = np.sin(zero_indexed_month*C)\n",
    "    month_cos = np.cos(zero_indexed_month*C)\n",
    "    return month_sin, month_cos\n",
    "\n",
    "query_features[\"month_sin\"], query_features[\"month_cos\"] = month_to_unit_circle(month_of_purchase)\n",
    "\n",
    "query_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32edb12d",
   "metadata": {},
   "source": [
    "Now we have all the query features. Let's load our retrieval model to generate the query embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4443c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hsml\n",
    "\n",
    "# connect with Hopsworks\n",
    "conn = hsml.connection()\n",
    "\n",
    "# get Hopsworks Model Serving\n",
    "ms = conn.get_model_serving()\n",
    "\n",
    "# get deployment object\n",
    "deployment = ms.get_deployment(\"querymodel\")\n",
    "\n",
    "query_emb = deployment.predict({\"instances\" : [query_features]})[\"predictions\"][0]\n",
    "\n",
    "query_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8eb934",
   "metadata": {},
   "source": [
    "We'll use this vector to retrieve the 100 closest candidate items. First we'll need to connect to our OpenSearch client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we need to feed this embedding to the open search engine.\n",
    "\n",
    "import hopsworks\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "connection = hopsworks.connection()\n",
    "project = connection.get_project()\n",
    "opensearch_api = project.get_opensearch_api()\n",
    "\n",
    "client = OpenSearch(**opensearch_api.get_default_py_config())\n",
    "\n",
    "index_name = opensearch_api.get_project_index(\"candidate_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee3c76",
   "metadata": {},
   "source": [
    "Next we'll do the actual search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5036f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for top 100 closest embeddings.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "k = 100\n",
    "\n",
    "query = {\n",
    "  \"size\": k,\n",
    "  \"query\": {\n",
    "    \"knn\": {\n",
    "      \"my_vector1\": {\n",
    "        \"vector\": query_emb,\n",
    "        \"k\": k\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body = query,\n",
    "    index = index_name\n",
    ")\n",
    "\n",
    "hits = response[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9888e",
   "metadata": {},
   "source": [
    "This query returns 100 candidate items. Note, however, that it might be the case that the customer has already bought one of these items. Let's find the article IDs of the items that the user has already bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a324e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_bought_items_ids = fs.sql(\n",
    "    f\"SELECT transactions_1.article_id from transactions_1 WHERE customer_id = '{customer_id}'\"\n",
    ").values.reshape(-1).tolist()\n",
    "\n",
    "print(already_bought_items_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf078c",
   "metadata": {},
   "source": [
    "We'll make sure to exclude these items from the set of candidate items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf579c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_list = []\n",
    "item_emb_list = []\n",
    "\n",
    "exclude_set = set(already_bought_items_ids)\n",
    "\n",
    "for el in hits:\n",
    "    item_id = str(el[\"_id\"])\n",
    "    if item_id in exclude_set:\n",
    "        continue\n",
    "    item_emb = el[\"_source\"][\"my_vector1\"]\n",
    "    item_id_list.append(item_id)\n",
    "    item_emb_list.append(item_emb)\n",
    "\n",
    "item_id_df = pd.DataFrame({\"article_id\" : item_id_list})\n",
    "item_emb_df = pd.DataFrame(item_emb_list).add_prefix(\"item_emb_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18df9d8",
   "metadata": {},
   "source": [
    "## Ranking Model\n",
    "\n",
    "We'll use the ranking model to make fine-grained predictions on these candidate items.\n",
    "This model uses a lot of features, namely:\n",
    "- All the features that the retrieval model uses.\n",
    "- The query embedding generated by the retrieval model.\n",
    "- The candidate embedding retrieved from OpenSearch.\n",
    "- Additional item features from the articles feature group/view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_fv = fs.get_feature_view(\"articles_fv\", 1)\n",
    "articles_features = [feat.name for feat in articles_fv.schema]\n",
    "articles_data = [articles_fv.get_feature_vector({\"article_id\" : article_id}) for article_id in item_id_list]\n",
    "articles_df = pd.DataFrame(data=articles_data, columns=articles_features)\n",
    "ranking_df = item_id_df.merge(articles_df, on=\"article_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eaf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_model_inputs = ranking_df.copy()\n",
    "\n",
    "# Add the user features we used with our retrieval model.\n",
    "ranking_model_inputs[\"age\"] = query_features[\"age\"]\n",
    "ranking_model_inputs[\"month_sin\"] = query_features[\"month_sin\"]\n",
    "ranking_model_inputs[\"month_cos\"] = query_features[\"month_cos\"]\n",
    "\n",
    "# Add query embeddings\n",
    "user_emb_df = pd.DataFrame([query_emb]).add_prefix(\"user_emb_\")\n",
    "for col in user_emb_df:\n",
    "    ranking_model_inputs.loc[:,col] = user_emb_df[col][0]\n",
    "\n",
    "# Add item embeddings.\n",
    "for col in item_emb_df:\n",
    "    ranking_model_inputs[col] = item_emb_df[col]\n",
    "    \n",
    "ranking_model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6637a",
   "metadata": {},
   "source": [
    "Now we have all the features we need for our ranking model. Let's load the ranking model so that we can get the input format correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d790de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_deployment = ms.get_deployment(\"rankingdeployment\")\n",
    "\n",
    "mr = conn.get_model_registry()\n",
    "model = mr.get_model(ranking_deployment.model_name, ranking_deployment.model_version)\n",
    "input_schema = model.model_schema[\"input_schema\"][\"columnar_schema\"]\n",
    "feat_names = [feat[\"name\"] for feat in input_schema]\n",
    "ranking_model_inputs = ranking_model_inputs[feat_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8675372c",
   "metadata": {},
   "source": [
    "Finally we can make our predictions. The ranking model will give us a score in range [0,1] (higher the better), and we'll print out the top-10 best predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the actual predictions.\n",
    "ranking_predictions = ranking_deployment.predict({\"inputs\" : ranking_model_inputs.values.tolist()})[\"predictions\"]\n",
    "ranking_scores = np.asarray(ranking_predictions)[:,1] # Scores of the positive class.\n",
    "ranking_df[\"ranking_score\"] = ranking_scores\n",
    "ranking_df.sort_values(\"ranking_score\", inplace=True, ascending=False)\n",
    "ranking_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
