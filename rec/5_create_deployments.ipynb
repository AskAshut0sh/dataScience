{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Deployment\n",
    "\n",
    "In this notebook, we'll create a deployment for our recommendation system.\n",
    "\n",
    "**NOTE Currently the transformer scripts are not implemented.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsml\n",
    "\n",
    "# connect to Hopsworks Model Registry\n",
    "\n",
    "conn = hsml.connection()\n",
    "mr = conn.get_model_registry()\n",
    "\n",
    "ranking_model = mr.get_best_model(\"ranking_model\", \"fscore\", \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hopsworks\n",
    "\n",
    "# get Hopsworks Dataset handle\n",
    "\n",
    "hopsworks_conn = hopsworks.connection()\n",
    "project = hopsworks_conn.get_project()\n",
    "dataset_api = project.get_dataset_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll deploy our ranking model. Since it is a CatBoost model we need to implement a `Predict` class that tells Hopsworks how to load the model and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ranking_predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ranking_predictor.py\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class Predict(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # NOTE: env var ARTIFACT_FILES_PATH has the path to the model artifact files\n",
    "        self.model = joblib.load(os.environ[\"ARTIFACT_FILES_PATH\"] + \"/ranking_model.pkl\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        features = inputs[0].pop(\"ranking_features\")\n",
    "        article_ids = inputs[0].pop(\"article_ids\")\n",
    "        \n",
    "        scores = self.model.predict_proba(features).tolist()\n",
    "        scores = np.asarray(scores)[:,1].tolist() # get scores of positive class\n",
    "        \n",
    "        return { \"scores\": scores, \"article_ids\": article_ids }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}: {percentage:.3f}%|{bar}| {n_fmt}/{total_fmt} elapsed<{elapsed} remaining<{remaining}",
       "colour": null,
       "elapsed": 0.01590871810913086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Uploading",
       "rate": null,
       "total": 633,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5029fe7598504ad7a3e627e0c25bd287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/633 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# copy predictor file into Hopsworks File System\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"ranking_predictor.py\", \"Resources\", overwrite=True)\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ranking_transformer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ranking_transformer.py\n",
    "\n",
    "import os\n",
    "import hsfs\n",
    "import hsml\n",
    "import hopsworks\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "class Transformer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # get feature store handle\n",
    "        fs_conn = hsfs.connection()\n",
    "        self.fs = fs_conn.get_feature_store()\n",
    "        \n",
    "        # get feature views\n",
    "        self.articles_fv = self.fs.get_feature_view(\"articles\", 1)\n",
    "        self.articles_features = [feat.name for feat in self.articles_fv.schema]\n",
    "        self.customer_fv = self.fs.get_feature_view(\"customers\", 1)\n",
    "        \n",
    "        # create opensearch client\n",
    "        hw_conn = hopsworks.connection()\n",
    "        project = hw_conn.get_project()\n",
    "        opensearch_api = project.get_opensearch_api()\n",
    "        self.os_client = OpenSearch(**opensearch_api.get_default_py_config())\n",
    "        self.candidate_index = opensearch_api.get_project_index(\"candidate_index\")\n",
    "\n",
    "        # get ranking model feature names\n",
    "        mm_conn = hsml.connection()\n",
    "        mr = mm_conn.get_model_registry()\n",
    "        model = mr.get_model(os.environ[\"MODEL_NAME\"], os.environ[\"MODEL_VERSION\"])\n",
    "        input_schema = model.model_schema[\"input_schema\"][\"columnar_schema\"]\n",
    "        self.ranking_model_feature_names = [feat[\"name\"] for feat in input_schema]\n",
    "    \n",
    "    \n",
    "    def preprocess(self, inputs):\n",
    "        inputs = inputs[\"inputs\"][0]\n",
    "        customer_id = inputs[\"customer_id\"]\n",
    "                \n",
    "        # search for candidates\n",
    "        hits = self.search_candidates(inputs[\"query_emb\"], k=100)\n",
    "        \n",
    "        # get already bought items\n",
    "        already_bought_items_ids = self.fs.sql(\n",
    "            f\"SELECT rec_featurestore.transactions_1.article_id from transactions_1 WHERE customer_id = '{customer_id}'\"\n",
    "        ).values.reshape(-1).tolist()\n",
    "        \n",
    "        # build dfs\n",
    "        item_id_list = []\n",
    "        item_emb_list = []\n",
    "        exclude_set = set(already_bought_items_ids)\n",
    "        for el in hits:\n",
    "            item_id = str(el[\"_id\"])\n",
    "            if item_id in exclude_set:\n",
    "                continue\n",
    "            item_emb = el[\"_source\"][\"my_vector1\"]\n",
    "            item_id_list.append(item_id)\n",
    "            item_emb_list.append(item_emb)\n",
    "        item_id_df = pd.DataFrame({\"article_id\" : item_id_list})\n",
    "        item_emb_df = pd.DataFrame(item_emb_list).add_prefix(\"item_emb_\")\n",
    "        \n",
    "        # get articles feature vectors\n",
    "        articles_data = [self.articles_fv.get_feature_vector({\"article_id\" : article_id}) for article_id in item_id_list]\n",
    "        articles_df = pd.DataFrame(data=articles_data, columns=self.articles_features)\n",
    "        ranking_model_inputs = item_id_df.merge(articles_df, on=\"article_id\", how=\"left\")\n",
    "        \n",
    "        # add the user features we used with our retrieval model.\n",
    "        customer_features = self.customer_fv.get_feature_vector({\"customer_id\": customer_id}) # get customer features\n",
    "        ranking_model_inputs[\"age\"] = customer_features[1]\n",
    "        ranking_model_inputs[\"month_sin\"] = inputs[\"month_sin\"]\n",
    "        ranking_model_inputs[\"month_cos\"] = inputs[\"month_cos\"]\n",
    "        ranking_model_inputs = ranking_model_inputs[self.ranking_model_feature_names]\n",
    "        \n",
    "        return { \"inputs\" : [{\"ranking_features\": ranking_model_inputs.values.tolist(), \"article_ids\": item_id_list}] }\n",
    "\n",
    "    \n",
    "    def postprocess(self, outputs):\n",
    "        preds = outputs[\"predictions\"]\n",
    "        ranking = list(zip(preds[\"scores\"], preds[\"article_ids\"])) # merge lists\n",
    "        ranking.sort(reverse=True) # sort by score (descending)\n",
    "        return { \"ranking\": ranking }\n",
    "    \n",
    "\n",
    "    def search_candidates(self, query_emb, k=100):\n",
    "        k = 100\n",
    "        query = {\n",
    "          \"size\": k,\n",
    "          \"query\": {\n",
    "            \"knn\": {\n",
    "              \"my_vector1\": {\n",
    "                \"vector\": query_emb,\n",
    "                \"k\": k\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        return self.os_client.search(\n",
    "            body = query,\n",
    "            index = self.candidate_index\n",
    "        )[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}: {percentage:.3f}%|{bar}| {n_fmt}/{total_fmt} elapsed<{elapsed} remaining<{remaining}",
       "colour": null,
       "elapsed": 0.01781296730041504,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Uploading",
       "rate": null,
       "total": 3914,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24b8c6ac0b44011a7691d27777fbe12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/3914 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# copy transformer file into Hopsworks File System\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"ranking_transformer.py\", \"Resources\", overwrite=True)\n",
    "transformer_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script must be uploaded to the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that in place, we can finally deploy our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment created, explore it at https://2176a0f0-3503-11ed-be64-b1a4781e5f0a.cloud.hopsworks.ai/p/135/deployments/14\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "from hsml.transformer import Transformer\n",
    "\n",
    "ranking_transformer=Transformer(script_file=transformer_script_path)\n",
    "\n",
    "ranking_deployment = ranking_model.deploy(name=\"rankingscores\",\n",
    "                                          script_file=predictor_script_path,\n",
    "                                          model_server=\"PYTHON\",\n",
    "                                          serving_tool=\"KSERVE\",\n",
    "                                          transformer=ranking_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment updated, explore it at https://2176a0f0-3503-11ed-be64-b1a4781e5f0a.cloud.hopsworks.ai/p/135/deployments/5\n"
     ]
    }
   ],
   "source": [
    "# # update deployment with new transformer\n",
    "\n",
    "# ms = conn.get_model_serving()\n",
    "# ranking_transformer=Transformer(script_file=transformer_script_path)\n",
    "# ranking_deployment = ms.get_deployment(\"rankingdeploy\")\n",
    "# ranking_deployment.script_file=predictor_script_path,\n",
    "# ranking_deployment.transformer=ranking_transformer\n",
    "# ranking_deployment.artifact_version=\"CREATE\"\n",
    "# ranking_deployment.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01584649085998535,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a69af6332fc45b988ac1518ff06ad96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModelServingException",
     "evalue": "Deployment has not reached the desired status within the expected awaiting time. Check the current status by using `.get_state()`, explore the server logs using `.get_logs()` or set a higher value for await_running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelServingException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-fb7ce8638349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mranking_deployment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsml/deployment.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, await_running)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serving_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mawait_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mawait_running\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mawait_stopped\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsml/engine/serving_engine.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, deployment_instance, await_status)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 )  # start deployment\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 state = self._poll_deployment_status(  # wait for status\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0mdeployment_instance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mPREDICTOR_STATE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATUS_RUNNING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsml/engine/serving_engine.py\u001b[0m in \u001b[0;36m_poll_deployment_status\u001b[0;34m(self, deployment_instance, status, await_status, update_progress)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m  \u001b[0;31m# deployment reached desired status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             raise ModelServingException(\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;34m\"Deployment has not reached the desired status within the expected awaiting time. Check the current status by using `.get_state()`, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m\"explore the server logs using `.get_logs()` or set a higher value for await_\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelServingException\u001b[0m: Deployment has not reached the desired status within the expected awaiting time. Check the current status by using `.get_state()`, explore the server logs using `.get_logs()` or set a higher value for await_running"
     ]
    }
   ],
   "source": [
    "ranking_deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://2176a0f0-3503-11ed-be64-b1a4781e5f0a.cloud.hopsworks.ai/p/135/deployments/11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://2176a0f0-3503-11ed-be64-b1a4781e5f0a.cloud.hopsworks.ai/p/135/deployments/11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment.get_logs(component=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: http://172.16.3.163:32080/v1/models/rankingdeploy:predict). Server response: \nHTTP code: 502, HTTP reason: Bad Gateway\n\n Check the model server logs by using `.get_logs()`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-a4289a4d2048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# test ranking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mranking_deployment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ranking_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsml/deployment.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serving_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsml/engine/serving_engine.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, deployment_instance, data)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n Check the model server logs by using `.get_logs()`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             )\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsml/engine/serving_engine.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, deployment_instance, data)\u001b[0m\n\u001b[1;32m    131\u001b[0m         )  # if not KServe, send request to Hopsworks\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             return self._serving_api.send_inference_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mdeployment_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthrough_hopsworks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsml/core/serving_api.py\u001b[0m in \u001b[0;36msend_inference_request\u001b[0;34m(self, deployment_instance, data, through_hopsworks)\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 )\n\u001b[0;32m--> 224\u001b[0;31m         return _client._send_request(\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsml/decorators.py\u001b[0m in \u001b[0;36mif_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNoHopsworksConnectionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mif_connected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsml/client/base.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRestAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: http://172.16.3.163:32080/v1/models/rankingdeploy:predict). Server response: \nHTTP code: 502, HTTP reason: Bad Gateway\n\n Check the model server logs by using `.get_logs()`"
     ]
    }
   ],
   "source": [
    "# test ranking deployment\n",
    "\n",
    "ms = conn.get_model_serving()\n",
    "ranking_deployment = ms.get_deployment(\"rankingdeploy\")\n",
    "test_ranking_input = {\"inputs\": [{\"month_sin\": 1.2246467991473532e-16,\n",
    "     \"query_emb\": [0.0126457736,\n",
    "      0.511958599,\n",
    "      -0.0947214961,\n",
    "      -0.293376535,\n",
    "      0.468758374,\n",
    "      0.88662535,\n",
    "      1.02364039,\n",
    "      -0.280806333,\n",
    "      0.228357121,\n",
    "      0.299074352,\n",
    "      -0.082454741,\n",
    "      -0.154759198,\n",
    "      0.920805335,\n",
    "      0.0531764328,\n",
    "      0.234613329,\n",
    "      1.12010455],\n",
    "     \"month_cos\": -1.0,\n",
    "     \"customer_id\": \"f6e35e1902674780464e8bc0f809cb5ae14883212b4f68b35b31de2facdb846f\"}]}\n",
    "\n",
    "# test ranking\n",
    "ranking_deployment.predict(test_ranking_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking_deployment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Model Deployment\n",
    "\n",
    "We start by deploying our user/query model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: No version provided for getting model `query_model`, defaulting to `1`.\n"
     ]
    }
   ],
   "source": [
    "# get query_model metadata object\n",
    "\n",
    "user_model = mr.get_model(\"query_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting querymodel_transformer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile querymodel_transformer.py\n",
    "\n",
    "import hsml\n",
    "import hsfs\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Transformer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        os.environ[\"ISTIO_ENDPOINT\"] = \"http://10.132.0.40:32080\"\n",
    "        os.environ[\"SERVING_API_KEY\"] = \"YvKSZyF6tuKLMkGy.gm8Vi8Sue43FwOkuXHSmz3sFsyhSSFqUCwCTs0SWgNek7DAfHWxJa222nVFHaY9H\"\n",
    "        \n",
    "        # get feature store handle\n",
    "        fs_conn = hsfs.connection()\n",
    "        self.fs = fs_conn.get_feature_store()\n",
    "        \n",
    "        # get feature views\n",
    "        self.customer_fv = self.fs.get_feature_view(\"customers\", 1)\n",
    "        \n",
    "        # get model management handle\n",
    "        mm_conn = hsml.connection() # model management connection\n",
    "        self.ms = mm_conn.get_model_serving()\n",
    "        \n",
    "        # get ranking deployment metadata object\n",
    "        self.ranking_server = self.ms.get_deployment(\"rankingdeploy\")\n",
    "        \n",
    "\n",
    "    def preprocess(self, inputs):\n",
    "        \n",
    "        # extract month\n",
    "        month_of_purchase = inputs.pop(\"month_of_purchase\")\n",
    "        \n",
    "        # get customer features\n",
    "        customer_features = self.customer_fv.get_feature_vector(inputs)\n",
    "        \n",
    "        # enrich inputs\n",
    "        inputs[\"age\"] = customer_features[1]\n",
    "        inputs[\"month_sin\"], inputs[\"month_cos\"] = self.month_to_unit_circle(month_of_purchase)\n",
    "        \n",
    "        return {\"instances\" : [inputs]}\n",
    "    \n",
    "    \n",
    "    def postprocess(self, outputs):\n",
    "        # get ordered ranking predictions\n",
    "        return self.ranking_server.predict({ \"inputs\": outputs[\"predictions\"] })\n",
    "\n",
    "    \n",
    "    def month_to_unit_circle(self, month):\n",
    "        zero_indexed_month = month - 1\n",
    "        C = 2*np.pi/12\n",
    "        month_sin = np.sin(zero_indexed_month*C)\n",
    "        month_cos = np.cos(zero_indexed_month*C)\n",
    "        return month_sin, month_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}: {percentage:.3f}%|{bar}| {n_fmt}/{total_fmt} elapsed<{elapsed} remaining<{remaining}",
       "colour": null,
       "elapsed": 0.015432357788085938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Uploading",
       "rate": null,
       "total": 1707,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0633eb99ac94813bf0d3894aaf30cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/1707 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# copy transformer file into Hopsworks File System\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"querymodel_transformer.py\", \"Models\", overwrite=True)\n",
    "transformer_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up a Tensorflow Serving server on KServe\n",
      "Deployment created, explore it at https://2176a0f0-3503-11ed-be64-b1a4781e5f0a.cloud.hopsworks.ai/p/135/deployments/9\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "from hsml.transformer import Transformer\n",
    "\n",
    "querymodel_transformer=Transformer(script_file=transformer_script_path)\n",
    "\n",
    "user_model_deployment = user_model.deploy(name=\"querymodel\",\n",
    "                                          serving_tool=\"KSERVE\",\n",
    "                                          transformer=querymodel_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update deployment with new transformer\n",
    "# from hsml.transformer import Transformer\n",
    "\n",
    "# ms = conn.get_model_serving()\n",
    "# ranking_deployment = ms.get_deployment(\"querymodel\")\n",
    "# querymodel_transformer=Transformer(script_file=transformer_script_path)\n",
    "# user_model_deployment.transformer=querymodel_transformer\n",
    "# user_model_deployment.artifact_version=\"CREATE\"\n",
    "# user_model_deployment.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have registered our deployment. To start it up we need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee47f3e0cbf14b879625df2bdc918684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_model_deployment.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the deployment by making a prediction on the input example we registered together with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ranking of recommendations by customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ranking': [[0.6154721480612619, '736049003'],\n",
       "  [0.5540913746584363, '675281003'],\n",
       "  [0.5304851740048736, '699671004'],\n",
       "  [0.5276218532463308, '662593001'],\n",
       "  [0.5095340171841166, '551045026'],\n",
       "  [0.5026730281370363, '690526005'],\n",
       "  [0.4875691666090818, '684968002'],\n",
       "  [0.48469640644251866, '733101002'],\n",
       "  [0.47009852360637683, '664485006'],\n",
       "  [0.4630649599819785, '792530001'],\n",
       "  [0.45387771054244613, '685284001'],\n",
       "  [0.43508248336589944, '636587004'],\n",
       "  [0.433700596348246, '687524004'],\n",
       "  [0.4305113042049035, '688873020'],\n",
       "  [0.4291665002462462, '657497007'],\n",
       "  [0.4158726009456486, '665477002'],\n",
       "  [0.40194335335264186, '691446002'],\n",
       "  [0.39916236382139625, '695601001'],\n",
       "  [0.37912135024778315, '582894001'],\n",
       "  [0.37088532655694806, '527687007'],\n",
       "  [0.37029970448593785, '662344004'],\n",
       "  [0.3521281188698809, '642047001'],\n",
       "  [0.343964885720146, '416157003'],\n",
       "  [0.34029184998960804, '607718001'],\n",
       "  [0.3394021012791623, '766081001'],\n",
       "  [0.3337815506689829, '642677001'],\n",
       "  [0.3334704472499205, '660459001'],\n",
       "  [0.3309789072572052, '766569001'],\n",
       "  [0.3273593671532633, '677546002'],\n",
       "  [0.31276305803660576, '684673004'],\n",
       "  [0.3098271502921269, '549607002'],\n",
       "  [0.30617882992328216, '557247020'],\n",
       "  [0.3058657839838698, '416157025'],\n",
       "  [0.30040265244427583, '712407001'],\n",
       "  [0.29548104089819954, '537895005'],\n",
       "  [0.2900169018215553, '633136008'],\n",
       "  [0.28330097111720703, '691595001'],\n",
       "  [0.27765461356060384, '574120001'],\n",
       "  [0.27605223682544683, '569206001'],\n",
       "  [0.2544113599179974, '740376001'],\n",
       "  [0.2465483189123175, '780320001'],\n",
       "  [0.22879888888755304, '809884001'],\n",
       "  [0.22226879408286435, '677347007'],\n",
       "  [0.218788088027871, '543689001'],\n",
       "  [0.21821132870174237, '681187001'],\n",
       "  [0.21451883930037668, '616711005'],\n",
       "  [0.21419348156849055, '633790002'],\n",
       "  [0.2129763011941628, '640124003'],\n",
       "  [0.20835571916165171, '652246001'],\n",
       "  [0.2082987707768369, '740812004'],\n",
       "  [0.20690319498178872, '539290014'],\n",
       "  [0.19274251414400081, '557247017'],\n",
       "  [0.17574704202382194, '810710002'],\n",
       "  [0.1744316414724128, '790645007'],\n",
       "  [0.173947074245299, '717593001'],\n",
       "  [0.173947074245299, '663003004'],\n",
       "  [0.1711686548668553, '806724003'],\n",
       "  [0.16268054203205087, '765558001'],\n",
       "  [0.15995848143480065, '793897003'],\n",
       "  [0.1581288523223293, '650759010'],\n",
       "  [0.15203157393146358, '734929004'],\n",
       "  [0.15044858621046406, '617835005'],\n",
       "  [0.14883572964527159, '617209001'],\n",
       "  [0.14361441400316435, '378447023'],\n",
       "  [0.14273803719019226, '496111023'],\n",
       "  [0.14252030573434807, '802153001'],\n",
       "  [0.1410443276185379, '803649002'],\n",
       "  [0.14021246728012035, '683941001'],\n",
       "  [0.1390973971250705, '672590001'],\n",
       "  [0.13026803888762528, '712123001'],\n",
       "  [0.13026803888762528, '656491001'],\n",
       "  [0.1281345579667301, '378135028'],\n",
       "  [0.1251683282746762, '616732001'],\n",
       "  [0.12348692508838313, '802549001'],\n",
       "  [0.11961971347863937, '666448007'],\n",
       "  [0.11961971347863937, '612574001'],\n",
       "  [0.11897993941389844, '635986002'],\n",
       "  [0.1183772883571491, '676990001'],\n",
       "  [0.11546968080467196, '656491006'],\n",
       "  [0.11546968080467196, '632832001'],\n",
       "  [0.10963500831475889, '625548003'],\n",
       "  [0.10696329741346237, '630891001'],\n",
       "  [0.10484585489743459, '665769001'],\n",
       "  [0.10231625598768768, '577713001'],\n",
       "  [0.10192822812578303, '663236002'],\n",
       "  [0.10076590692435512, '651724002'],\n",
       "  [0.09920238780034747, '626054001'],\n",
       "  [0.09904252393807277, '695972003'],\n",
       "  [0.09331124697214802, '666448005'],\n",
       "  [0.0895535280708372, '754323002'],\n",
       "  [0.08803388640604426, '637667001'],\n",
       "  [0.0862528370663872, '627769005'],\n",
       "  [0.08457666455325583, '719002001'],\n",
       "  [0.0807813222775954, '776185004'],\n",
       "  [0.0781590296259039, '660830005'],\n",
       "  [0.07369106476121959, '643220002'],\n",
       "  [0.06762688075350866, '511923002'],\n",
       "  [0.06230922733864265, '645275001'],\n",
       "  [0.059729295748597915, '627214004'],\n",
       "  [0.05437224065361691, '633740002']]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_id = \"f6e35e1902674780464e8bc0f809cb5ae14883212b4f68b35b31de2facdb846f\"\n",
    "month_of_purchase = 7\n",
    "\n",
    "query_emb = user_model_deployment.predict({\"customer_id\": customer_id, \"month_of_purchase\": month_of_purchase})\n",
    "query_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stop the deployment when we're not using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_model_deployment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-16 12:44:33,825 INFO: => ELASTIC_ENDPOINT: https://172.16.4.231:9200\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "2022-09-16 12:44:34,010 INFO: => ELASTIC_CONFIG: {'hosts': [{'host': None, 'port': None}], 'http_compress': False, 'headers': {'Authorization': 'eyJraWQiOiIyMDg1IiwidHlwIjoiSldUIiwiYWxnIjoiSFM1MTIifQ.eyJwaWlkIjozMDI3MCwic3ViIjoicmVjIiwiZXhwTGVld2F5Ijo2MCwicm9sZXMiOiJkYXRhX293bmVyIiwiaXNzIjoiaG9wc3dvcmtzQGxvZ2ljYWxjbG9ja3MuY29tIiwiZXhwIjoxNjYzMzM0MDc0LCJpYXQiOjE2NjMzMzIyNzQsImp0aSI6ImQzZDBjYTM5LTU4NmEtNDE1ZC1iMTBlLTRmMTUyMzFjZDllZiIsInBuIjoicmVjIn0.SAyGqZ8N_F4Lk802JIJ0fNT3RYixi78ZjOHTSauyC_ldgRCb3ous9rn6hyHgHLpufWMuehMvfeK6xcG5ju-BBA'}, 'use_ssl': True, 'verify_certs': True, 'ssl_assert_hostname': False, 'ca_certs': '/tmp/ca_chain.pem'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import hopsworks\n",
    "logging.info(\"=> ELASTIC_ENDPOINT: \" + os.getenv(\"ELASTIC_ENDPOINT\", \"Not found\"))\n",
    "os.environ[\"ELASTIC_ENDPOINT\"] = os.environ[\"ELASTIC_ENDPOINT\"][8:]\n",
    "hw_conn = hopsworks.connection()\n",
    "project = hw_conn.get_project()\n",
    "opensearch_api = project.get_opensearch_api()\n",
    "logging.info(\"=> ELASTIC_CONFIG: \" + str(opensearch_api.get_default_py_config()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ELASTIC_ENDPOINT\"] = \"https://172.16.4.231:9200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from furl import furl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = furl(os.environ[\"ELASTIC_ENDPOINT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172.16.4.231'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url.host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: No training dataset version was provided to initialise serving. Defaulting to version 1.\n",
      "SADeprecationWarning: The LegacyRow.items() method is deprecated and will be removed in a future release.  Use the Row._mapping attribute, i.e., 'row._mapping.items()'. (deprecated since: 1.4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['f6e35e1902674780464e8bc0f809cb5ae14883212b4f68b35b31de2facdb846f',\n",
       " 22.0,\n",
       " '2ca0feec76d39bdcef6c050770afab673e6ef0b1f5c126637fa83342b103bf35']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "conn = hsfs.connection()\n",
    "fs = conn.get_feature_store()\n",
    "fview = fs.get_feature_view(\"customers\", version=1)\n",
    "fview.get_feature_vector({\"customer_id\": \"f6e35e1902674780464e8bc0f809cb5ae14883212b4f68b35b31de2facdb846f\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}