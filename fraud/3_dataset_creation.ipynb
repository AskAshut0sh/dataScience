{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud Tutorial - Dataset Creation\n",
    "\n",
    "In this notebook, we will create the actual dataset that we will train our model on. In particular, we will:\n",
    "1. Select the features we want to train our model on.\n",
    "2. Specify how the features should be preprocessed.\n",
    "3. Create a dataset split for training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "conn = hsfs.connection()\n",
    "fs = conn.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "We start by selecting all the features we want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: No version provided for getting feature group `transactions`, defaulting to `1`.\n",
      "VersionWarning: No version provided for getting feature group `transactions_4h_aggs`, defaulting to `1`.\n",
      "VersionWarning: No version provided for getting feature group `transactions_add_info`, defaulting to `1`.\n",
      "UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg2.category</th>\n",
       "      <th>fg2.amount</th>\n",
       "      <th>fg2.fraud_label</th>\n",
       "      <th>fg0.trans_volume_mavg</th>\n",
       "      <th>fg0.trans_volume_mstd</th>\n",
       "      <th>fg0.trans_freq</th>\n",
       "      <th>fg0.loc_delta</th>\n",
       "      <th>fg0.loc_delta_mavg</th>\n",
       "      <th>fg1.age_at_transaction</th>\n",
       "      <th>fg1.days_until_card_expires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health/Beauty</td>\n",
       "      <td>50.49</td>\n",
       "      <td>0</td>\n",
       "      <td>50.49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199013</td>\n",
       "      <td>0.199013</td>\n",
       "      <td>93.527820</td>\n",
       "      <td>1561.665197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Restaurant/Cafeteria</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0</td>\n",
       "      <td>6.69</td>\n",
       "      <td>7.254916</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.201949</td>\n",
       "      <td>0.117487</td>\n",
       "      <td>37.868375</td>\n",
       "      <td>1020.860197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Health/Beauty</td>\n",
       "      <td>78.70</td>\n",
       "      <td>0</td>\n",
       "      <td>78.70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090711</td>\n",
       "      <td>0.090711</td>\n",
       "      <td>18.028501</td>\n",
       "      <td>1024.225127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grocery</td>\n",
       "      <td>77.75</td>\n",
       "      <td>0</td>\n",
       "      <td>77.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.128094</td>\n",
       "      <td>0.128094</td>\n",
       "      <td>58.379903</td>\n",
       "      <td>1720.178391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grocery</td>\n",
       "      <td>18.76</td>\n",
       "      <td>0</td>\n",
       "      <td>39.72</td>\n",
       "      <td>29.641916</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.606323</td>\n",
       "      <td>0.394127</td>\n",
       "      <td>35.957443</td>\n",
       "      <td>-336.186377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fg2.category  fg2.amount  fg2.fraud_label  fg0.trans_volume_mavg  \\\n",
       "0         Health/Beauty       50.49                0                  50.49   \n",
       "1  Restaurant/Cafeteria        1.56                0                   6.69   \n",
       "2         Health/Beauty       78.70                0                  78.70   \n",
       "3               Grocery       77.75                0                  77.75   \n",
       "4               Grocery       18.76                0                  39.72   \n",
       "\n",
       "   fg0.trans_volume_mstd  fg0.trans_freq  fg0.loc_delta  fg0.loc_delta_mavg  \\\n",
       "0               0.000000             1.0       0.199013            0.199013   \n",
       "1               7.254916             2.0       0.201949            0.117487   \n",
       "2               0.000000             1.0       0.090711            0.090711   \n",
       "3               0.000000             1.0       0.128094            0.128094   \n",
       "4              29.641916             2.0       0.606323            0.394127   \n",
       "\n",
       "   fg1.age_at_transaction  fg1.days_until_card_expires  \n",
       "0               93.527820                  1561.665197  \n",
       "1               37.868375                  1020.860197  \n",
       "2               18.028501                  1024.225127  \n",
       "3               58.379903                  1720.178391  \n",
       "4               35.957443                  -336.186377  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load feature groups.\n",
    "trans_fg = fs.get_feature_group(\"transactions\")\n",
    "trans_4h_aggs_fg = fs.get_feature_group(\"transactions_4h_aggs\")\n",
    "trans_add_info_fg = fs.get_feature_group(\"transactions_add_info\")\n",
    "\n",
    "# Select features for training data.\n",
    "ds_query = trans_fg.select([\"category\", \"amount\", \"fraud_label\"])\\\n",
    "    .join(trans_4h_aggs_fg.select_except([\"tid\"]), on=\"tid\")\\\n",
    "    .join(trans_add_info_fg.select_except([\"tid\"]), on=\"tid\")\n",
    "\n",
    "ds_query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we computed the aggregate features in `transactions_4h_aggs` using 4-hour windows. If we wanted to experiment with other window lengths, e.g. 24 hours, we could easily create a separate feature group for that with the same schema as `transactions_4h_aggs` and include that in the join. To prevent feature name clash we would need to include a prefix argument in the join:\n",
    "\n",
    "```python\n",
    "    ds_query = ds_query.join(trans_24h_aggs_fg.select_except([\"tid\"]), on=\"tid\", prefix=\"24h\")\n",
    "```\n",
    "\n",
    "This illustrates yet another usage of features groups, namely that they can be used to namespace features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Functions\n",
    "\n",
    "We will preprocess our data using *min-max scaling* on numerical features and *one-hot encoding* on categorical features. To do this we simply define a mapping between our features and transformation functions. This ensures that transformation functions such as *min-max scaling* are fitted only on the training data (and not the validation/test data), which ensures that there is no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformation functions.\n",
    "min_max_scaler = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "label_encoder = fs.get_transformation_function(name=\"label_encoder\")\n",
    "\n",
    "# Map features to transformations.\n",
    "transformation_functions = {\n",
    "    \"category\": label_encoder,\n",
    "    \"amount\": min_max_scaler,\n",
    "    \"trans_volume_mavg\": min_max_scaler,\n",
    "    \"trans_volume_mstd\": min_max_scaler,\n",
    "    \"trans_freq\": min_max_scaler,\n",
    "    \"loc_delta\": min_max_scaler,\n",
    "    \"loc_delta_mavg\": min_max_scaler,\n",
    "    \"age_at_transaction\": min_max_scaler,\n",
    "    \"days_until_card_expires\": min_max_scaler,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Creation\n",
    "\n",
    "Finally we create the dataset using `fs.create_training_dataset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add chronological split here.\n",
    "td = fs.create_training_dataset(\n",
    "    name=\"transactions_dataset_splitted\",\n",
    "    label=[\"fraud_label\"],\n",
    "    data_format=\"csv\",\n",
    "    transformation_functions=transformation_functions,\n",
    "    splits={'train': 70, 'validation': 30},\n",
    "    train_split=\"train\"\n",
    ")\n",
    "\n",
    "# We can save the dataset using the query alone.\n",
    "td.save(ds_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sanity check that the transformation functions have been applied by loading the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'td' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jacob/Desktop/git-proj/hopsworks/3_dataset_creation.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jacob/Desktop/git-proj/hopsworks/3_dataset_creation.ipynb#ch0000010?line=0'>1</a>\u001b[0m td\u001b[39m.\u001b[39mread(\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'td' is not defined"
     ]
    }
   ],
   "source": [
    "td.read(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.read(\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "In the next notebook, we will train a model on the dataset we created in this notebook."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
